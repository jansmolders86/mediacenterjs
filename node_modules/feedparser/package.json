{
  "name": "feedparser",
  "author": {
    "name": "Dan MacTough",
    "email": "danmactough@gmail.com"
  },
  "description": "Robust RSS Atom and RDF feed parsing using sax js",
  "version": "0.11.0",
  "keywords": [
    "rss",
    "feed",
    "atom",
    "rdf",
    "xml",
    "syndication"
  ],
  "homepage": "http://github.com/danmactough/node-feedparser",
  "repository": {
    "type": "git",
    "url": "git://github.com/danmactough/node-feedparser.git"
  },
  "bugs": {
    "url": "http://github.com/danmactough/node-feedparser/issues"
  },
  "main": "./main.js",
  "engines": {
    "node": ">= 0.8.0"
  },
  "dependencies": {
    "sax": "0.5.x",
    "request": "2.9.x",
    "addressparser": "~0.1.3",
    "array-indexofobject": "0.0.1"
  },
  "devDependencies": {
    "mocha": "1.x",
    "buffet": "0.4.x"
  },
  "scripts": {
    "test": "./node_modules/mocha/bin/mocha"
  },
  "readme": "[![Build Status](https://secure.travis-ci.org/danmactough/node-feedparser.png?branch=master)](https://travis-ci.org/danmactough/node-feedparser)\n#  Feedparser - Robust RSS, Atom, and RDF feed parsing in Node.js\n\nThis module adds methods for RSS, Atom, and RDF feed parsing in node.js using\nIsaac Schlueter's [sax](https://github.com/isaacs/sax-js) parser.\n\n## Requirements\n\n- [sax](https://github.com/isaacs/sax-js)\n- [request](https://github.com/mikeal/request)\n- [addressparser](https://github.com/andris9/addressparser)\n\n## Installation\n\n```bash\nnpm install feedparser\n```\n\n## Changes since v0.9.x\n\nThe module now exports `parseString`, `parseFile`, `parseUrl`, and `parseStream`\nas static functions. You no longer need to create a `FeedParser` instance or use\nthe prototype methods. Due to confusion about how to implement those methods in\napplication code, using the prototype methods is now **DEPRECATED**.\n\nAs a major enhancement, Feedparser is now able to properly handle XML\nnamespaces, including those in sadistic feeds that define a non-default\nnamespace for the main feed elements.\n\n### Old API (Deprecated)\n```javascript\nvar FeedParser = require('feedparser')\n  , parser = new FeedParser()\n  ;\nparser.on('article', console.log);\nparser.parseString(string);\n```\n\n### New API\n```javascript\nvar feedparser = require('feedparser');\nfeedparser.parseString(string)\n  .on('article', console.log);\n```\n\n## Usage\n\n### parser.parseString(string, [options], [callback])\n\n- `string` - the contents of the feed\n\n### parser.parseFile(filename, [options], [callback])\n\n- `filename` - a local filename or remote url\n\n### parser.parseUrl(url, [options], [callback])\n\nThe first argument can be either a url or a `request` options object. The only\nrequired option is uri, all others are optional. See\n[request](https://github.com/mikeal/request#requestoptions-callback) for details\nabout what that `request` options object might look like.\n\n- `url` - fully qualified uri or a parsed url object from url.parse()\n\n### parser.parseStream(readableStream, [options], [callback])\n\n- `readableStream` - a [Readable Stream](http://nodejs.org/api/stream.html#stream_readable_stream)\n\n### options\n\n- `normalize` - Set to `false` to override Feedparser's default behavior,\n  which is to parse feeds into an object that contains the generic properties\n  patterned after (although not identical to) the RSS 2.0 format, regardless\n  of the feed's format.\n\n- `addmeta` - Set to `false` to override Feedparser's default behavior, which\n  is to add the feed's `meta` information to each `article`.\n\n- `feedurl` - The url (string) of the feed. FeedParser is very good at\n  resolving relative urls in feeds. But some feeds use relative urls without\n  declaring the `xml:base` attribute any place in the feed. This is perfectly\n  valid, but if we are parsing the feed with the `parseString`, `parseFile`,\n  or `parseStream` method, we don't know know the feed's url before we start\n  parsing the feed and trying to resolve those relative urls. If we discover\n  the feed's url, we will go back and resolve the relative urls we've already\n  seen, but this takes a little time (not much). If you want to be sure we\n  never have to re-resolve relative urls (or if FeedParser is failing to\n  properly resolve relative urls), you should set `feedurl`.\n\n## Examples\n\n```javascript\nvar feedparser = require('feedparser')\n  , fs = require('fs') // used in the examples below\n  ;\n```\n\n### Use as an EventEmitter\n\n(For brevity in this pseudo-code, I'm not handling errors. But you need to\nhandle errors in your code.)\n\n```javascript\n\nfunction callback (article) {\n  console.log('Got article: %s', JSON.stringify(article));\n}\n\n// You can give a local file path to parseFile()\nfeedparser.parseFile('./feed')\n  .on('article', callback);\n\n// For libxml compatibility, you can also give a URL to parseFile()\nfeedparser.parseFile('http://cyber.law.harvard.edu/rss/examples/rss2sample.xml')\n  .on('article', callback);\n\n// Or, you can give that URL to parseUrl()\nfeedparser.parseUrl('http://cyber.law.harvard.edu/rss/examples/rss2sample.xml')\n  .on('article', callback);\n\n// But you should probably be using conditional GETs and passing the results to\n// parseString() or piping it right into the stream, if possible\n\nvar request = require('request');\nvar reqObj = {'uri': 'http://cyber.law.harvard.edu/rss/examples/rss2sample.xml',\n              'headers': {'If-Modified-Since' : <your cached 'lastModified' value>,\n                          'If-None-Match' : <your cached 'etag' value>}};\n\n// parseString()\nrequest(reqObj, function (err, response, body){\n  feedparser.parseString(body)\n    .on('article', callback);\n});\n\n// Stream piping\nrequest(reqObj).pipe(feedparser.stream);\n\n// Or you could try letting feedparser handle working with request (experimental)\nfeedparser.parseUrl(reqObj)\n  .on('response', function (response){\n    // do something like save the HTTP headers for a future request\n  })\n  .on('article', callback);\n\n// Using the stream interface with a file (or string)\n// A good alternative to parseFile() or parseString() when you have a large local file\nfeedparser.parseStream(fs.createReadStream('./feed'))\n  .on('article', callback);\n// Or\nfs.createReadStream('./feed').pipe(feedparser.stream)\n  .on('article', callback);\n```\n\n#### Events\n* `complete` - called with `meta` and `articles` when parsing is complete\n* `end` - called with no parameters when parsing is complete or aborted (e.g., due to error)\n* `error` - called with `error` whenever there is a an error of any kind (SAXEror, Feedparser error, request error, etc.)\n* `meta` - called with `meta` when it has been parsed\n* `article` - called with a single `article` when each article has been parsed\n* `response` - called with the HTTP `response` only when a url has been fetched via parseUrl or parseFile\n* `304` - called with no parameters when when a url has been fetched with a conditional GET via parseUrl or parseFile and the remote server responds with '304 Not Modified'\n\n### Use with a callback\n\nWhen the feed is finished being parsed, if you provide a callback, it gets\ncalled with three parameters: error, meta, and articles.\n\n```javascript\nfunction callback (error, meta, articles){\n  if (error) console.error(error);\n  else {\n    console.log('Feed info');\n    console.log('%s - %s - %s', meta.title, meta.link, meta.xmlurl);\n    console.log('Articles');\n    articles.forEach(function (article){\n      console.log('%s - %s (%s)', article.date, article.title, article.link);\n    });\n  }\n}\n\nfeedparser.parseFile('./feed', callback);\n\n// To use the stream interface with a callback, you *MUST* use parseStream(), not piping\nfeedparser.parseStream(fs.createReadStream('./feed'), callback);\n```\n\n## What is the parsed output produced by feedparser?\n\nFeedparser parses each feed into a `meta` portion and one or more `articles`.\n\nRegardless of the format of the feed, the `meta` and each `article` contain a\nuniform set of generic properties patterned after (although not identical to)\nthe RSS 2.0 format, as well as all of the properties originally contained in the\nfeed. So, for example, an Atom feed may have a `meta.description` property, but\nit will also have a `meta['atom:subtitle']` property.\n\nThe purpose of the generic properties is to provide the user a uniform interface\nfor accessing a feed's information without needing to know the feed's format\n(i.e., RSS versus Atom) or having to worry about handling the differences\nbetween the formats. However, the original information is also there, in case\nyou need it. In addition, Feedparser supports some popular namespace extensions\n(or portions of them), such as portions of the `itunes`, `media`, `feedburner`\nand `pheedo` extensions. So, for example, if a feed article contains either an\n`itunes:image` or `media:thumbnail`, the url for that image will be contained in\nthe article's `image.url` property.\n\nAll generic properties are \"pre-initialized\" to `null` (or empty arrays or\nobjects for certain properties). This should save you from having to do a lot of\nchecking for `undefined`, such as, for example, when you are using jade\ntemplates.\n\nIn addition, all properties (and namespace prefixes) use only lowercase letters,\nregardless of how they were capitalized in the original feed. (\"xmlUrl\" and\n\"pubDate\" also are still used to provide backwards compatibility.) This decision\nplaces ease-of-use over purity -- hopefully, you will never need to think about\nwhether you should camelCase \"pubDate\" ever again.\n\n### List of meta propreties\n\n* title\n* description\n* link (website link)\n* xmlurl (the canonical link to the feed, as specified by the feed)\n* date (most recent update)\n* pubdate (original published date)\n* author\n* language\n* image (an Object containing `url` and `title` properties)\n* favicon (a link to the favicon -- only provided by Atom feeds)\n* copyright\n* generator\n* categories (an Array of Strings)\n\n### List of article propreties\n\n* title\n* description (frequently, the full article content)\n* summary (frequently, an excerpt of the article content)\n* link\n* origlink (when FeedBurner or Pheedo puts a special tracking url in the `link` property, `origlink` contains the original link)\n* date (most recent update)\n* pubdate (original published date)\n* author\n* guid (a unique identifier for the article)\n* comments (a link to the article's comments section)\n* image (an Object containing `url` and `title` properties)\n* categories (an Array of Strings)\n* source (an Object containing `url` and `title` properties pointing to the original source for an article; see the [RSS Spec](http://cyber.law.harvard.edu/rss/rss.html#ltsourcegtSubelementOfLtitemgt) for an explanation of this element)\n* enclosures (an Array of Objects, each representing a podcast or other enclosure and having a `url` property and possibly `type` and `length` properties)\n* meta (an Object containing all the feed meta properties; especially handy when using the EventEmitter interface to listen to `article` emissions)\n\n## Contributors\n\nThe following are the major contributors of `node-feedparser` (in no specific\norder).\n\n* Dan MacTough ([danmactough](http://github.com/danmactough))\n\nAlthough `node-feedparser` no longer shares any code with `node-easyrss`, it was\nthe original inspiration and a starting point.\n\n## License\n\n(The MIT License)\n\nCopyright (c) 2011-2012 Dan MacTough &lt;danmactough@gmail.com&gt;\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the 'Software'), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
  "readmeFilename": "README.md",
  "_id": "feedparser@0.11.0",
  "dist": {
    "shasum": "9508b2812a5150550d306a413da02502a1f3ead3"
  },
  "_from": "feedparser"
}
